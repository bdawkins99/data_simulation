---
output: 
  github_document:
    toc: true
    toc_depth: 2
params:
  author:
    input: text
    label: "What is your name?"
    value: "Bryan Dawkins"
  path_analysis:
    input: text
    label: "Specify folder name for analyses:"
    value: "analysis"
  num_samples:
    input: numeric
    label: "How many samples should simulated datasets have?"
    value: 100
  num_variables:
    input: numeric
    label: "How many total independent variables (or features) should simulated datasets have?"
    value: 100
  percent_imbalance:
    input: numeric
    label: "What proportion of samples should be in the 'positive' class? (Choose a number > 0 and < 1)"
    value: 0.5
  percent_signals:
    input: numeric
    label: "What proportion of features should be functional (i.e., have significant main effect or interaction effect)?"
    value: 0.1
  main_bias:
    input: numeric
    label: "How strong should effect sizes be for main effects? (Note: Effect size increases as parameter value increases; values should be > 0)"
    value: 1
  interaction_bias:
    input: numeric
    label: "How strong should effect sizes be for interaction effects? (Note: Effect size decreases as parameter value increases; values should be > 0)"
    value: 0.2
  percent_mixed:
    input: numeric
    label: "What proportion of functional features (i.e., those simulated to have significant statistical effect) should have main effect?"
    value: 0.5
  class_label:
    input: text
    label: "What is the name of the binary outcome (i.e., dependent variable) in simulated datasets?"
    value: "class"
  save_output:
    input: radio
    label: Save all output?
    value: no
    choices:
    - yes
    - no
author: '`r params$author`'
title: "Simulated Datasets With Binary Outcomes"
date: '`r Sys.Date()`'
editor_options: 
  chunk_output_type: inline
---

```{r setup}
library(knitr)
options(knitr.table.format = "html")
opts_chunk$set(message = FALSE, warning = FALSE, cache = FALSE)
```

```{r load-pkgs, message = FALSE, warning = FALSE, echo = FALSE, results = 'hide'}
library(here)
library(privateEC)
library(dplyr)
library(ggplot2)
library(flextable)
library(officer)
library(DT)
library(captioner)
library(npdr)
library(tidyr)
library(GGally)
```

```{r}
tables <- captioner(prefix = "Table ", suffix = ". ", style = "b", style_prefix = TRUE, auto_space = FALSE)
figures <- captioner(prefix = "Figure ", suffix = ". ", style = "b", style_prefix = TRUE, auto_space = FALSE)

figures("interactionFig", "The simulation of gene expression data with differential co-expression network effects begins with a gene network with given connectivity and degree distribution, such as scale-free (Step 1). Initially the data set, with N genes and M subjects, has correlation structure that does not differ between groups (Step 2). A detailed algorithm for Step 2 is given in Figure 2. Briefly, the data set is initialized to a random Gaussian matrix, and then genes are changed to be proportional to others based on their connections in the adjacency matrix (Step 1). The strength of the correlation is regulated by a Gaussian (0, noise) variable, where smaller noise creates stronger correlation between genes. To create differentially co-expressed genes (Step 3), we arbitrarily split the M columns of data into two groups (cases and controls) and select random genes for permutation (red xâ€™s) in the cases group. Note that this permutation is distinct from the permutation used to assess significance. This permutation keeps the simulated group means the same, so there are no main effects, but disrupts the wiring or correlation in the cases group between the target gene and the genes it was connected to in the adjacency matrix from Step 1. The co-expression in the healthy control group is left unchanged, resulting in a complex data set with an embedded differential co-expression network.", display = FALSE)
```

```{r paths-and-scripts}
script_dir <- here::here(params$path_analysis, "scripts")
output_dir <- here::here(params$path_analysis, "output")
plot_dir <- here::here(params$path_analysis, "plots")
report_dir <- here::here(params$path_analysis, "reports")

source(here::here(script_dir, "main-effect_plus_interaction-effect_continuous-features_simulation.R"))
source(here::here(script_dir, "create_html_datatable.R"))
source(here::here(script_dir, "process_sim_yaml.R"))
source(here::here(script_dir, "calc-uni.R"))
```

```{r sim-args}
sim_args <- process_sim_yaml(params)
```

# Create a simulated dataset
The following is an example where I am generating a simulated dataset which can be used for assessing machine learning algorithm performance in detecting features with significant main effects and interaction effects, respectively, for a binary outcome (e.g., case-control). The simulated dataset has `r params$num_samples` samples, and `r params$num_variables` total independent variables (`r params$percent_signals*100`% with significant statistical effect on the outcome). Out of the total number of features with significant statistical effect, `r {(1-params$percent_mixed)*100}`% will have only a main effect and the remaining `r params$percent_mixed*100`% will have only interaction effect (no main effect). 

Both main effects and interaction effects were generated using the `createSimulation()` function in the `privateEC` R library. Main effects were created by employing the following linear model:  

$$X_{ij} = \beta_i y_i + \epsilon_{ij}\text{,}$$

where $X{ij}$ is the value of the $i^{\text{th}}$ feature for the $j^{\text{th}}$ sample instance, $\beta_i$ is the coefficient of the $i^{\text{th}}$ feature, $y_i \in \{-1, 1\}$ is the binary class of the $j^{\text{th}}$ sample instance, and $\epsilon_{ij} \sim \mathcal{N}(0, 1)$ is random noise from a standard normal distribution.^1^


Interaction effects were based on a random graph (or network), where connected features are differentially correlated between class groups, exhibiting strong pairwise correlation in the 'negative' group (e.g., controls) but completely disrupted/destroyed correlation in the 'positive' group (e.g., cases); see `r figures("interactionFig", display = "cite")`.^2^

```{r interactionFig, fig.align = "left", out.width = "100%", fig.cap = figures("interactionFig"), fig.id=FALSE}
knitr::include_graphics(here::here(plot_dir, "interaction-sim_fig.png"))
```

## Output Object

Columns named `simvar1`, `simvar2`, ..., have either main effect or interaction effect (but not both). The remaining columns, named `var1`, `var1`, ..., are just random Gaussian noise.
```{r create-sim, out.width = "100%", fig.align = "center"}

sim.dats <- do.call(sim_mixed_fn, sim_args)

head(sim.dats[, c(1:15, ncol(sim.dats))], n = 10) |> 
  mutate(across(where(is.numeric), ~round(.x, digits = 3))) |>
  flextable() |> 
  set_table_properties(align = "center")
```

## Calculate Variable Importance

Variable importance can be calculated in a multitude of different ways. Here I am using a method called Nearest-neighbor Projected Distance Regression (NPDR), which allows for hypothesis testing and a measure of statistical significance (i.e., p-values), covariate adjustment (e.g., age, sex, ancestry, etc), in addition to feature selection using a LASSO penalty.^3^

The output from `npdr()` is a dataframe with multiple columns. The variable importance (`beta.Z.att`) is a standardized effect size, and the corresponding p-value (`pval.att`) is calculated from a one-sided hypothesis test; the bonferroni-adusted p-value (`pval.adj`) is also present. As shown in the table below, the features with the largest importance scores are those that were simulated to have a main effect or interaction effect, respectively.
```{r run-npdr, out.width = "70%", fig.align = "center"}
npdr_res <- npdr(outcome = "class",
                 dataset = sim.dats,
                 regression.type = "binomial",
                 attr.diff.type = "numeric-abs",
                 nbd.method = "relieff",
                 nbd.metric = "manhattan", 
                 knn = 0)

head(npdr_res, n = 15) |> 
  mutate(across(c(2,3, ncol(npdr_res)), ~format(.x, digits = 3))) |> 
  mutate(across(where(is.numeric), ~format(round(.x, digits = 3), nsmall = 3))) |>
  flextable() |> 
  set_table_properties(align = "center")
```

## Visualize Main effects
```{r visualize-MainEffects, fig.align = "center", out.width = "90%"}

# Main Effect Features
plot_df <- sim.dats |> 
  select(all_of(c(paste0("simvar", 1:5), "class"))) |> 
  mutate(Outcome = factor(case_when(
    class == 1 ~ "Case",
    TRUE ~ "Control"
  ), levels = c("Case", "Control"))) |> 
  pivot_longer(cols = paste0("simvar", 1:5), values_to = "Center-scaled Feature Value", names_to = "Feature") |> 
  mutate(Feature = as.factor(Feature))

ggplot(plot_df, aes(x = Feature, y = `Center-scaled Feature Value`, color = Outcome, fill = Outcome, alpha = Outcome)) +
  geom_boxplot(color = "darkgray", alpha = 0.5) +
  geom_point(position = position_jitterdodge(seed = 1234), alpha = 0.7) +
  scale_color_manual(breaks = c("Case", "Control"), values = c("#7a0177", "#225ea8")) +
  scale_fill_manual(breaks = c("Case", "Control"), values = c("#7a0177", "#225ea8")) +
  theme_bw() + 
  ggtitle("Simulated Features With Main Effect") +
  theme(axis.title.x = element_blank(),
        legend.position = "top",
        legend.text = element_text(size = 12),
        legend.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.y = element_text(size = 14, color = "#252525"),
        plot.title = element_text(size = 18, face = "bold", color = "black", hjust = 0.5))

```

## Visualize Interaction Effects
```{r visualize-InteractionEffects, fig.align = "center", out.width = "100%"}

# Interaction Effect Features
plot_df <- sim.dats |> 
  select(all_of(c(paste0("simvar", 6:10), "class"))) |> 
  mutate(Outcome = factor(case_when(
    class == 1 ~ "Case",
    TRUE ~ "Control"
  ), levels = c("Case", "Control"))) |> 
  pivot_longer(cols = paste0("simvar", 6:10), values_to = "Center-scaled Feature Value", names_to = "Feature") |> 
  mutate(Feature = as.factor(Feature))

plot_df <- sim.dats |> 
  mutate(Outcome = factor(case_when(
    class == 1 ~ "Case",
    TRUE ~ "Control"
  ), levels = c("Case", "Control")))

cols <- c("Case" = "#7a0177", "Control" = "#225ea8")
alphs <- c("Case" = 0.6, "Control" = 0.6)
ggpairs(plot_df, aes(color = Outcome, fill = Outcome, alpha = 0.7),
        columns = 6:10) +
  discrete_scale(aesthetics = c("fill", "color"), palette = grDevices::colorRampPalette(c("#7a0177", "#225ea8"))) +
  ggtitle("Simulated Features With Interaction Effect") +
  theme_bw() +
  theme(plot.title = element_text(size = 18, face = "bold", color = "black", hjust = 0.5))
```

## Standard Univariate Statistics for Detecting Main Effects

### t-test
```{r, out.width = "70%", fig.align = "center"}
head(create_stat_tab(.data = sim.dats, 
                     test.name = "t-test", 
                     response.name = "class") |> 
       select(-all_of(c("estimate1", "estimate2", "parameter", "method", "formula"))), n = 10) |> 
  format_stat_tab(n.digits = 3) |> 
  flextable() |> 
  set_table_properties(align = "center")
```

### Kolmogorov-Smirnov Test
```{r, out.width = "70%", fig.align = "center"}
head(create_stat_tab(.data = sim.dats, 
                     test.name = "ks-test", 
                     response.name = "class") |> 
       select(-all_of(c("method", "formula", "exact"))), n = 10) |> 
  format_stat_tab(n.digits = 3) |> 
  flextable() |> 
  set_table_properties(align = "center")
```

### Wilcoxon Rank Sum (or Mann-Whitney) Test
```{r, out.width = "70%", fig.align = "center"}
head(create_stat_tab(.data = sim.dats, 
                     test.name = "wilcox-test", 
                     response.name = "class") |> 
       select(-all_of(c("method", "formula"))), n = 10) |> 
  format_stat_tab(n.digits = 3) |> 
  flextable() |> 
  set_table_properties(align = "center")
```

### Kruskal-Wallis Test
```{r, out.width = "70%", fig.align = "center"}

head(create_stat_tab(.data = sim.dats, 
                     test.name = "kw-test", 
                     response.name = "class") |> 
       select(-all_of(c("parameter", "method", "formula"))), n = 10) |> 
  format_stat_tab(n.digits = 3) |> 
  flextable() |> 
  set_table_properties(align = "center")
```

### Test Statistic for Main Effect in Linear Model
```{r, out.width = "70%", fig.align = "center"}

head(create_stat_tab(.data = sim.dats, 
                     test.name = "lm-test", 
                     response.name = "class"), n = 10) |> 
  format_stat_tab(n.digits = 3) |> 
  flextable() |> 
  set_table_properties(align = "center")
```


## References
1. Leek, J. T., and J. D. Storey. "Capturing Heterogeneity in Gene Expression Studies by Surrogate Variable Analysis." PLoS Genet 3, no. 9 (Sep 2007): 1724-35. https://dx.doi.org/10.1371/journal.pgen.0030161.
2. Lareau, C. A., B. C. White, A. L. Oberg, and B. A. McKinney. "Differential Co-Expression Network Centrality and Machine Learning Feature Selection for Identifying Susceptibility Hubs in Networks with Scale-Free Structure." BioData Min 8 (2015): 5. https://dx.doi.org/10.1186/s13040-015-0040-x.
3. Le, Trang T, Bryan A Dawkins, and Brett A McKinney. "Nearest-Neighbor Projected-Distance Regression (NPDR) for Detecting Network Interactions with Adjustments for Multiple Tests and Confounding." Bioinformatics 36, no. 9 (2020): 2770-77. Accessed 5/6/2022. https://dx.doi.org/10.1093/bioinformatics/btaa024.













